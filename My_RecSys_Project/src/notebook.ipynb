{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f02f8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Log Count: 14126324\n",
      "   user  item        time      genre\n",
      "0    11  4643  1230782529     Action\n",
      "1    11  4643  1230782529  Adventure\n",
      "2    11  4643  1230782529      Drama\n",
      "3    11  4643  1230782529     Sci-Fi\n",
      "4    11   170  1230782534     Action\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DATA_PATH =\"../train/\"\n",
    "# 1. 데이터 로드\n",
    "# train_ratings는 csv, genres는 tsv 파일입니다.\n",
    "\n",
    "train_ratings = pd.read_csv(os.path.join(DATA_PATH,'train_ratings.csv'))\n",
    "df_genres = pd.read_csv(os.path.join(DATA_PATH,'genres.tsv'),sep='\\t')\n",
    "train_ratings.head(5)\n",
    "df_genres.head(5)\n",
    "# 2. 데이터 병합 (Merge)\n",
    "# train_ratings를 기준으로 df_genres를 붙입니다.\n",
    "# TODO: on에는 공통 컬럼명, how에는 병합 방식을 적어주세요.\n",
    "df_merged = pd.merge(train_ratings, df_genres, on='item', how='left')\n",
    "\n",
    "# 3. 결측치 처리 (Fillna)\n",
    "# 장르가 없는 경우(NaN) 튕겨내지 말고 'Unknown'으로 채워줍니다.\n",
    "df_merged['genre'] = df_merged['genre'].fillna('Unknown')\n",
    "\n",
    "# 검증\n",
    "print(f\"Total Log Count: {len(df_merged)}\")\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bac2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 14063604, Valid: 31360, Test: 31360\n"
     ]
    }
   ],
   "source": [
    "## 실험 설계 무엇을 input label 로 할지 나누는 작업\n",
    "\n",
    "## 검증 전략 각 유저가 마지막으로 본 아이템 딱 1개를 정답으로 숨겨두고  나머지 과거 데이터만 가지고 맞출 수 있는지\n",
    "## validate로 구성하는 방법\n",
    "df_sorted=df_merged.sort_values(['user','time'])\n",
    "\n",
    "df_sorted.head()\n",
    "## duplicated로 각 중복 user id중 가장 마지막을 추출함\n",
    "df_test = df_sorted.drop_duplicates(subset=['user'], keep='last')\n",
    "# 가장 마지막 인덱스를 통해서 드롭함\n",
    "df_temp = df_sorted.drop(df_test.index)\n",
    "df_val = df_temp.drop_duplicates(subset=\"user\",keep='last')\n",
    "\n",
    "df_train = df_temp.drop(df_val.index)\n",
    "# 검증\n",
    "print(f\"Train: {len(df_train)}, Valid: {len(df_val)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6aef47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Pairs: [((5445, 5445), 3116), ((4306, 4306), 2968), ((8961, 8961), 2736), ((1215, 1215), 2362), ((29, 29), 2296)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import itertools as it  # (A) 라이브러리 이름\n",
    "# 윈도우를 5개로 정하나요?\n",
    "def train_cooc_dict(df, window_size=5):\n",
    "    # counter 이름을 왜 cooc라고 지은거지\n",
    "    cooc_counts = Counter()\n",
    "    \n",
    "    # user로 묶는데 item을 []로 감싸면 무슨효과로 item이 시간순 리스트가 되는거죠\n",
    "    user_item_list = df.groupby('user')['item'].apply(list)\n",
    "    \n",
    "    for items in user_item_list:\n",
    "    \n",
    "        # 아이템 리스트가 [A,B,C,D]\n",
    "        for i in range(len(items)):\n",
    "            # 현재 타깃 i에 대해서 윈도우 만큼의 애들을 자름 파이썬이라 index 오류는 안남..\n",
    "            context_items = items[i+i : i+1+window_size]\n",
    "            \n",
    "            # 윈도우에 있는 context_items에서 이웃을 짝짔는다\n",
    "            for neigbor in context_items:\n",
    "                # (A) -> (B) 방향\n",
    "                cooc_counts[(items[i], neigbor)] += 1\n",
    "                # (B) -> (A) 방향\n",
    "                cooc_counts[(neigbor,items[i])]+= 1\n",
    "    return cooc_counts\n",
    "cooc_dict = train_cooc_dict(df_train, window_size=5)\n",
    "print(f\"Top 5 Pairs: {cooc_dict.most_common(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "220b6d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'>\n",
      "item4643의 연관 아이템 Top3:\n",
      "[(4643, 246), (1882, 21), (6537, 18)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def cooc_to_map(cooc_counts):\n",
    "    # item_id를 키로 하고 값은 Counter인 딕셔너리?\n",
    "    item_cooc_map = defaultdict(Counter)\n",
    "    \n",
    "    for (item_i, item_j), count in cooc_counts.items():\n",
    "        # 두가지 아이템조합의 dict -> 2차원 배열로 만들어서 관리한다\n",
    "        #그래서 두가지 아이템이 있으면 그 카운트를 뱉는 맵을 생성하는거군요\n",
    "        item_cooc_map[item_i][item_j] = count\n",
    "        \n",
    "    return item_cooc_map\n",
    "item_map = cooc_to_map(cooc_dict)\n",
    "\n",
    "test_item = list(item_map.keys())[0]\n",
    "print(type(item_map.keys()))\n",
    "print(f\"item{test_item}의 연관 아이템 Top3:\")\n",
    "#mostcommon이 어떻게 쓰이는지도 까먹은 것 같네요\n",
    "print(item_map[test_item].most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b43730b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 11의 Last Item: 7153\n",
      "추천된 후보군 개수: 50\n",
      "후보군 Top 10: [7153, 2571, 4993, 5952, 318, 5445, 527, 4034, 1500, 58559]\n"
     ]
    }
   ],
   "source": [
    "# 1. 유저별 과거 기록 가져오기 (Retrieval의 힌트로 사용)\n",
    "# train_df는 이미 시간순 정렬이 되어 있습니다.\n",
    "user_history_dict = df_train.groupby('user')['item'].apply(list).to_dict()\n",
    "\n",
    "global_popular = df_train['item'].value_counts().head(50).index.tolist()\n",
    "\n",
    "def generate_candidates_robust(user_id, history_dict, cooc_map, n_candidates=50):\n",
    "    candidates = []\n",
    "    \n",
    "    # 1. Retrieval 시도 (History & Co-occurrence)\n",
    "    if user_id in history_dict:\n",
    "        last_item = history_dict[user_id][-1]\n",
    "        \n",
    "        if last_item in cooc_map:\n",
    "            # 짝꿍 아이템 가져오기\n",
    "            top_items = cooc_map[last_item].most_common(n_candidates)\n",
    "            candidates = [item for item, score in top_items]\n",
    "    \n",
    "    # 2. [수정된 부분] 모자란 개수만큼 인기 아이템으로 채우기 (Fallback)\n",
    "    if len(candidates) < n_candidates:\n",
    "        for item in global_popular:\n",
    "            if item not in candidates: # 중복 방지\n",
    "                candidates.append(item)\n",
    "                # 개수가 다 차면 중단\n",
    "                if len(candidates) >= n_candidates:\n",
    "                    break\n",
    "                    \n",
    "    return candidates\n",
    "\n",
    "# 검증: Valid Set의 첫 번째 유저에 대해 테스트\n",
    "test_user = df_val['user'].iloc[0]\n",
    "candidates = generate_candidates_robust(test_user, user_history_dict, item_map)\n",
    "\n",
    "print(f\"User {test_user}의 Last Item: {user_history_dict[test_user][-1]}\")\n",
    "print(f\"추천된 후보군 개수: {len(candidates)}\")\n",
    "print(f\"후보군 Top 10: {candidates[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f912afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Retrieval Recall@50: 0.5991\n",
      "Retrieval Recall@10: 0.5991\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 4. Candidate Generation & Evaluation (Recall@50)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. 빠른 조회를 위한 유저 히스토리 (Train Set 기준)\n",
    "# 검색 속도를 위해 DataFrame -> Dictionary 변환\n",
    "train_history = df_train.groupby('user')['item'].apply(list).to_dict()\n",
    "\n",
    "def evaluate_retrieval_strict(val_data, cooc_map, history_dict, top_k=50):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    \n",
    "    for _, row in val_data.iterrows():\n",
    "        user = row['user']\n",
    "        truth = row['item']\n",
    "        \n",
    "        # [수정 1] Fallback이 적용된 함수를 사용해 무조건 후보를 받아옴\n",
    "        recommendations = generate_candidates_robust(user, history_dict, cooc_map, n_candidates=top_k)\n",
    "            \n",
    "        # [수정 2] continue 없이 무조건 채점\n",
    "        if truth in recommendations:\n",
    "            hits += 1\n",
    "        \n",
    "        total += 1 # 분모는 무조건 증가\n",
    "    \n",
    "    return hits / total if total > 0 else 0\n",
    "\n",
    "# 다시 측정해보면 점수가 살짝 떨어질 수 있습니다 (하지만 이게 진짜 실력입니다)\n",
    "real_recall = evaluate_retrieval_strict(df_val, item_map, train_history, top_k=50)\n",
    "print(f\"Real Retrieval Recall@50: {real_recall:.4f}\")\n",
    "\n",
    "print(f\"Retrieval Recall@10: {real_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e815a989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Train Size: 1127086\n",
      "label\n",
      "0    1108310\n",
      "1      18776\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def make_ranking_dataset(val_data, cooc_map, history_dict, top_k=50):\n",
    "    ranking_data = []\n",
    "    \n",
    "    # tqdm이 있다면: for _, row in tqdm(val_data.iterrows()):\n",
    "    for _, row in val_data.iterrows():\n",
    "        user = row['user']\n",
    "        truth = row['item']\n",
    "        \n",
    "        last_item = history_dict[user][-1]\n",
    "        \n",
    "        if last_item in cooc_map:\n",
    "            candidates_with_score = cooc_map[last_item].most_common(top_k)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        for cand_item, score in candidates_with_score:\n",
    "            label = 1 if truth == cand_item else 0\n",
    "            \n",
    "            ranking_data.append({\n",
    "                'user': user,\n",
    "                'item': cand_item,\n",
    "                'cooc_score': score,\n",
    "                'label': label\n",
    "            })\n",
    "    \n",
    "    # [Fix] return은 for문이 완전히 끝난 뒤에 실행되어야 합니다. (들여쓰기 주의!)\n",
    "    return pd.DataFrame(ranking_data)\n",
    "\n",
    "# 다시 실행\n",
    "df_rank_train = make_ranking_dataset(df_val, item_map, train_history, top_k=50)\n",
    "\n",
    "# 검증\n",
    "print(f\"Ranking Train Size: {len(df_rank_train)}\")\n",
    "print(df_rank_train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67c57542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  cooc_score  label      genre\n",
      "0    11  7153        1880      0     Action\n",
      "1    11  2571         392      0     Action\n",
      "2    11  4993         357      0  Adventure\n",
      "3    11  5952         319      0  Adventure\n",
      "4    11   318         199      0      Crime\n"
     ]
    }
   ],
   "source": [
    "## Item Meta 생성\n",
    "#Merge : df_rank_train 에 장르 정보를 붙인다\n",
    "## 아이템별 대표 장르 1개 추출\n",
    "df_item_features = df_genres.drop_duplicates(subset=['item'],keep='first')\n",
    "\n",
    "# 2. Ranking 데이터에 장르 붙이기 \n",
    "# User, Item,Score, Label + df_item_features(Item, Genre)\n",
    "df_final_train = pd.merge(df_rank_train, df_item_features, on='item',how='left')\n",
    "\n",
    "df_final_train['genre'] = df_final_train['genre'].fillna('Unknown')\n",
    "\n",
    "print(df_final_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bdc8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost Ranker...\n",
      "0:\tlearn: 0.4846665\ttotal: 287ms\tremaining: 2m 23s\n",
      "100:\tlearn: 0.0531592\ttotal: 28.5s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.0500265\ttotal: 58.6s\tremaining: 1m 27s\n",
      "300:\tlearn: 0.0480232\ttotal: 1m 29s\tremaining: 59.5s\n",
      "400:\tlearn: 0.0467933\ttotal: 1m 58s\tremaining: 29.3s\n",
      "499:\tlearn: 0.0460221\ttotal: 2m 26s\tremaining: 0us\n",
      "\n",
      "Feature Importance:\n",
      "cooc_score: 94.26\n",
      "genre: 5.74\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 7. Train Ranking Model (CatBoost)\n",
    "# ---------------------------------------------------------\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1. 학습에 사용할 Feature(문제)와 Label(정답) 정의\n",
    "# 우리는 '점수'와 '장르' 두 가지 힌트만 줍니다. (심플 이즈 베스트)\n",
    "features = ['cooc_score', 'genre']\n",
    "X = df_final_train[features]\n",
    "y = df_final_train['label']\n",
    "\n",
    "# 2. CatBoost 모델 선언\n",
    "# task_type=\"GPU\"를 쓰면 RTX 3070을 쓸 수 있지만, 설정이 까다로우니 일단 CPU로 돌립니다. (충분히 빠릅니다)\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,       # 반복 학습 횟수\n",
    "    learning_rate=0.1,    # 학습 속도\n",
    "    depth=6,              # 의사결정나무의 깊이\n",
    "    cat_features=['genre'], # [핵심] \"장르는 글자니까 네가 알아서 처리해\"\n",
    "    verbose=100           # 100번마다 로그 출력\n",
    ")\n",
    "\n",
    "# 3. 학습 시작 (Fit)\n",
    "print(\"Training CatBoost Ranker...\")\n",
    "model.fit(X, y)\n",
    "\n",
    "# 4. 중요도 확인 (어떤 힌트가 정답을 맞추는 데 중요했을까?)\n",
    "print(\"\\nFeature Importance:\")\n",
    "for name, imp in zip(features, model.get_feature_importance()):\n",
    "    print(f\"{name}: {imp:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ead0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Final Reranker on Test Set...\n",
      "Final Test Recall@50: 0.5072\n"
     ]
    }
   ],
   "source": [
    "def evaluate_reranker(test_data, model, cooc_map, history_dict, item_meta, top_k=50):\n",
    "    hits = 0 \n",
    "    total = 0\n",
    "    \n",
    "    # Test Set의 모든 유저에 대해 반복\n",
    "    for _, row in test_data.iterrows():\n",
    "        user = row['user']\n",
    "        truth = row['item']\n",
    "        \n",
    "        if user not in history_dict: continue\n",
    "        last_item = history_dict[user][-1]\n",
    "        \n",
    "        if last_item not in cooc_map:\n",
    "            recommendations = []\n",
    "        else:\n",
    "            # 후보 50개와 점수\n",
    "            candidates = cooc_map[last_item].most_common(top_k)\n",
    "            \n",
    "            #2. Reranking을 위한 데이터 프레임\n",
    "            # 모델에게 이 50개 채점해주라는 표를 만든다\n",
    "            inf_df = pd.DataFrame(candidates, columns=['item', 'cooc_score'])\n",
    "            # 장르 정보 붙이기\n",
    "            inf_df = pd.merge(inf_df, item_meta, on='item', how='left')\n",
    "            inf_df['genre'] = inf_df['genre'].fillna('Unknown')\n",
    "            # 3. CatBoost 예측\n",
    "            # 정답일 확률을 물어보는 함수?\n",
    "            # [:, 1] 클래스 1(정답일 확률을 가져온다??)\n",
    "            scores = model.predict_proba(inf_df[['cooc_score','genre']])[:,1]\n",
    "            \n",
    "            # 4. 점수순으로 다시 정렬 (Reranking)\n",
    "            inf_df['pred_score'] = scores\n",
    "            inf_df = inf_df.sort_values('pred_score', ascending=False)\n",
    "            \n",
    "            # 최종 추천 리스트 (아이템 ID만 추출)\n",
    "            recommendations = inf_df['item'].tolist()\n",
    "        \n",
    "        if truth in recommendations[:top_k]:\n",
    "            hits += 1 \n",
    "        total += 1\n",
    "    return hits/ total if total > 0 else 0\n",
    "print(\"Evaluating Final Reranker on Test Set...\")\n",
    "final_recall = evaluate_reranker(df_test, model, item_map, train_history, df_item_features, top_k=50)\n",
    "\n",
    "print(f\"Final Test Recall@50: {final_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47e6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Robust Recall@10...\n",
      "✅ Real Recall@10: 0.4869\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Robust Evaluation: 통계 왜곡 방지 버전\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 0. 비상용 인기 아이템 50개 미리 준비 (Train 기준)\n",
    "global_popular = df_train['item'].value_counts().head(50).index.tolist()\n",
    "\n",
    "def evaluate_robust(val_data, model, cooc_map, history_dict, item_meta, cand_n=200, top_k=10):\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 전체 유저에 대해 예외 없이 반복\n",
    "    for _, row in val_data.iterrows():\n",
    "        user = row['user']\n",
    "        truth = row['item']\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # [Case 1] 기록이 있는 유저 (정상적인 개인화 추천)\n",
    "        if user in history_dict:\n",
    "            last_item = history_dict[user][-1]\n",
    "            \n",
    "            if last_item in cooc_map:\n",
    "                # 1. Retrieval\n",
    "                candidates = cooc_map[last_item].most_common(cand_n)\n",
    "                \n",
    "                # 2. Reranking Setup\n",
    "                inf_df = pd.DataFrame(candidates, columns=['item', 'cooc_score'])\n",
    "                inf_df = pd.merge(inf_df, item_meta, on='item', how='left')\n",
    "                inf_df['genre'] = inf_df['genre'].fillna('Unknown')\n",
    "                \n",
    "                # 3. CatBoost Scoring\n",
    "                scores = model.predict_proba(inf_df[['cooc_score', 'genre']])[:, 1]\n",
    "                inf_df['pred_score'] = scores\n",
    "                inf_df = inf_df.sort_values('pred_score', ascending=False)\n",
    "                \n",
    "                recommendations = inf_df['item'].tolist()\n",
    "\n",
    "        # [Case 2] 추천 개수가 모자라거나, 기록이 없는 경우 (Fallback)\n",
    "        # 인기 아이템으로 빈자리를 채웁니다.\n",
    "        if len(recommendations) < top_k:\n",
    "            for item in global_popular:\n",
    "                if item not in recommendations:\n",
    "                    recommendations.append(item)\n",
    "                    if len(recommendations) >= top_k:\n",
    "                        break\n",
    "        \n",
    "        # 상위 k개 자르기\n",
    "        final_recs = recommendations[:top_k]\n",
    "        \n",
    "        # [핵심] continue 없이 무조건 채점 (Hits Check)\n",
    "        if truth in final_recs:\n",
    "            hits += 1\n",
    "            \n",
    "        total += 1  # 분모(Total)는 무조건 증가\n",
    "        \n",
    "    return hits / total if total > 0 else 0\n",
    "\n",
    "# 실행: 진짜 실력 확인\n",
    "print(\"Checking Robust Recall@10...\")\n",
    "real_recall = evaluate_robust(df_test, model, item_map, train_history, df_item_features, cand_n=50, top_k=10)\n",
    "\n",
    "print(f\"✅ Real Recall@10: {real_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "089872d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Target Users: 31360명\n",
      "Generating Predictions for 31360 Users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [01:16<00:00, 412.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Shape: (313600, 2)\n",
      "   user  item\n",
      "0    11  7153\n",
      "1    11  5952\n",
      "2    11  8961\n",
      "3    11  1198\n",
      "4    11  1639\n",
      "5    11   260\n",
      "6    11  4886\n",
      "7    11  2571\n",
      "8    11  4993\n",
      "9    11  2268\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 9. Generate Final Submission (Correction)\n",
    "# ---------------------------------------------------------\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0. 비상용 인기 아이템 50개 미리 준비 (Train 데이터 기준)\n",
    "# (이건 추천할 게 없을 때를 대비한 '비상약'입니다)\n",
    "global_popular = df_train['item'].value_counts().head(50).index.tolist()\n",
    "\n",
    "def generate_submission(target_users, model, cooc_map, history_dict, item_meta, cand_n=200, top_k=10):\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Generating Predictions for {len(target_users)} Users...\")\n",
    "    \n",
    "    # tqdm으로 진행 상황 확인\n",
    "    for user in tqdm(target_users):\n",
    "        recommendations = []\n",
    "        \n",
    "        # --- A. 개인화 추천 시도 (Retrieval + Reranking) ---\n",
    "        # 1. 유저의 과거 기록(Train)이 있는지 확인\n",
    "        if user in history_dict:\n",
    "            last_item = history_dict[user][-1]\n",
    "            \n",
    "            # 2. Retrieval: 짝꿍 아이템이 있는지 확인\n",
    "            if last_item in cooc_map:\n",
    "                candidates = cooc_map[last_item].most_common(cand_n)\n",
    "                \n",
    "                # 3. Reranking Data Setup\n",
    "                inf_df = pd.DataFrame(candidates, columns=['item', 'cooc_score'])\n",
    "                inf_df = pd.merge(inf_df, item_meta, on='item', how='left')\n",
    "                inf_df['genre'] = inf_df['genre'].fillna('Unknown')\n",
    "                \n",
    "                # 4. CatBoost Scoring (확률 계산)\n",
    "                scores = model.predict_proba(inf_df[['cooc_score', 'genre']])[:, 1]\n",
    "                \n",
    "                # 5. Sort (점수 높은 순 정렬)\n",
    "                inf_df['pred_score'] = scores\n",
    "                inf_df = inf_df.sort_values('pred_score', ascending=False)\n",
    "                recommendations = inf_df['item'].tolist()\n",
    "        \n",
    "        # --- B. 빈칸 채우기 (Fallback) ---\n",
    "        # 추천이 아예 없거나(Cold Start), 10개보다 적은 경우 인기 아이템으로 채움\n",
    "        if len(recommendations) < top_k:\n",
    "            for item in global_popular:\n",
    "                if item not in recommendations: # 중복 방지\n",
    "                    recommendations.append(item)\n",
    "                    if len(recommendations) >= top_k:\n",
    "                        break\n",
    "        \n",
    "        # 최종 Top 10 자르기\n",
    "        final_recs = recommendations[:top_k]\n",
    "        \n",
    "        # 결과 저장\n",
    "        for item in final_recs:\n",
    "            results.append({\n",
    "                'user': user,\n",
    "                'item': item\n",
    "            })\n",
    "            \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 실행 파트 (수정됨)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. [핵심 수정] 외부 파일 대신, 우리 Test Set에서 유저 리스트를 직접 추출합니다.\n",
    "# df_test에는 모든 유저가 1줄씩 들어있으므로, 유저 ID 리스트와 같습니다.\n",
    "target_user_list = df_test['user'].unique()\n",
    "\n",
    "print(f\"Total Target Users: {len(target_user_list)}명\")\n",
    "\n",
    "# 2. 함수 실행\n",
    "df_final = generate_submission(target_user_list, model, item_map, train_history, df_item_features)\n",
    "\n",
    "# 3. CSV 저장\n",
    "df_final.to_csv('my_final_submission.csv', index=False)\n",
    "\n",
    "# 4. 검증 (유저 수 x 10 = 313,600 줄이 나와야 성공!)\n",
    "print(f\"\\nFinal Shape: {df_final.shape}\")\n",
    "print(df_final.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e64e3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Real Submission with Full History...\n",
      "Generating Predictions for 31360 Users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [01:08<00:00, 457.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Submission Saved! Shape: (313600, 2)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 10. Final Logic Fix (Full History Update)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. 모든 데이터를 하나로 합칩니다. (가장 최신 기록을 찾기 위해)\n",
    "# df_train, df_val, df_test를 모두 합쳐야 '진짜 마지막 아이템'을 알 수 있습니다.\n",
    "df_all = pd.concat([df_train, df_val, df_test])\n",
    "\n",
    "# 2. 전체 데이터 기준으로 최신 History Dict를 다시 만듭니다.\n",
    "# 이제 user_id를 넣으면, Train 기간이 아니라 '데이터 전체 기간'의 맨 마지막 아이템이 나옵니다.\n",
    "final_history_dict = df_all.groupby('user')['item'].apply(list).to_dict()\n",
    "\n",
    "# 3. (선택사항) Co-occurrence Map도 전체 데이터로 다시 만들면 더 좋습니다.\n",
    "# 시간이 걸린다면 기존 map을 써도 되지만, 성능을 위해선 업데이트를 권장합니다.\n",
    "# print(\"Re-training Co-occurrence Map with Full Data...\")\n",
    "# final_cooc_map = train_cooc_map(df_all, window_size=5)\n",
    "# 일단은 기존 map을 그대로 써도 점수는 확 오를 겁니다.\n",
    "final_cooc_map = item_map \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 다시 제출 파일 생성\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 4. 업데이트된 final_history_dict를 넣고 다시 실행\n",
    "print(\"Generating Real Submission with Full History...\")\n",
    "\n",
    "df_final_submission = generate_submission(\n",
    "    target_user_list,    # 아까 만든 전체 유저 리스트\n",
    "    model,               # 학습된 CatBoost 모델\n",
    "    final_cooc_map,      # (선택) 전체 데이터로 업데이트된 맵 or 기존 맵\n",
    "    final_history_dict,  # [핵심] Train+Val+Test가 모두 합쳐진 최신 기록\n",
    "    df_item_features,    # 아이템 메타 정보\n",
    "    cand_n=50, \n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "# 5. 저장\n",
    "df_final_submission.to_csv('submission_fixed.csv', index=False)\n",
    "print(f\"Fixed Submission Saved! Shape: {df_final_submission.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
